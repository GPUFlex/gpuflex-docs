# Key Priorities

Our top priority is not a single factor, but all three – cost efficiency, infrastructure control, and scalability – achieved simultaneously through this hybrid design. We refuse to trade one for another; instead, the business model is engineered to optimize each:

## Cost Efficiency

Adopting decentralized model will dramatically cut costs. By sourcing idle GPUs from individuals and third-party providers, we avoid heavy capital expenses and pass savings to customers. Vast.ai’s experience shows that decentralization can yield “cost efficiency through decentralization,” connecting users to a global pool of GPU providers (from hobbyists’ rigs to smaller cloud centers) . This broad supply keeps prices low via competition and high resource utilization. Dynamic pricing (discussed below) further ensures users only pay market-fair rates, minimizing waste.

## Control & Reliability

To ensure enterprise-grade reliability and control, we will maintain a subset of our own infrastructure. While a pure peer-to-peer marketplace can have variable stability, our platform-owned 10 - 15% of servers gives us direct control over critical resources. These company-owned GPUs provide a reliable backbone – guaranteeing availability during surges, enforcing security standards, and serving customers with strict performance or compliance needs. By blending in-house nodes with vetted community hardware, we uphold quality assurance while still benefiting from decentralized scale.

## Scalability

Elastic scalability is inherent in this hybrid model. The 85 - 90% user-hosted portion means capacity can grow organically as more hosts join for “global liquidity” of GPUs that allows tapping into thousands of devices on-demand . This provides virtually unlimited scaling potential without the platform having to purchase every GPU. Meanwhile, the 15% platform-owned fleet acts as a buffer for scaling: we can quickly add our own servers in key regions or high-demand zones to meet surges, ensuring a smooth user experience. By combining these, we can seamlessly scale from a few GPUs to hundreds or more, handling everything from small experiments to large enterprise workloads without a hitch. In short, user-contributed hardware gives us breadth of scale, and platform hardware gives us depth of control – together enabling both rapid growth and stable operation.\


